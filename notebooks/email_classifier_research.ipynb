{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'cat_emails_v2(in).csv'\n",
    "\n",
    "with open(path, 'r', encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    raw_lines = f.readlines()\n",
    "\n",
    "records = []\n",
    "in_record = False\n",
    "current_category = None\n",
    "email_parts = []\n",
    "\n",
    "for line in raw_lines[1:]:\n",
    "\n",
    "    if not in_record:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        if line.lstrip().startswith('\"'):\n",
    "            in_record = True\n",
    "            email_parts = []\n",
    "\n",
    "            l = line.strip()\n",
    "            if l.startswith('\"'):\n",
    "                l = l[1:]\n",
    "\n",
    "            idx = l.find(',')\n",
    "            if idx == -1:\n",
    "\n",
    "                in_record = False\n",
    "                current_category = None\n",
    "                email_parts = []\n",
    "                continue\n",
    "\n",
    "            current_category = l[:idx].strip()\n",
    "\n",
    "            rest = l[idx+1:]\n",
    "            email_parts.append(rest)\n",
    "\n",
    "    else:\n",
    "        email_parts.append(line)\n",
    "\n",
    "        if line.strip().endswith('\"\"\"'):\n",
    "\n",
    "            full_text = \"\".join(email_parts)\n",
    "\n",
    "            full_text_clean = (\n",
    "                full_text.replace('\"\"\"', '')\n",
    "                         .replace('\"\"', '\"')\n",
    "                         .replace('\"', '')\n",
    "                         .strip()\n",
    "            )\n",
    "\n",
    "            records.append((current_category, full_text_clean))\n",
    "\n",
    "            in_record = False\n",
    "            current_category = None\n",
    "            email_parts = []\n",
    "\n",
    "\n",
    "data = pd.DataFrame(records, columns = ['category', 'email_text'])\n",
    "\n",
    "data.to_csv('clean_emails.csv', index = False)\n",
    "\n",
    "print('Parsed emails: ', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['category'].astype('category').cat.codes\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size = 500, random_state = 42, stratify = data['label'])\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset  = Dataset.from_pandas(test_data)\n",
    "\n",
    "model_name = 'distilbert-base-german-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['email_text'], truncation = True, padding = 'max_length', max_length = 256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched = True)\n",
    "test_dataset = test_dataset.map(tokenize, batched = True)\n",
    "\n",
    "train_dataset.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type = 'torch', columns = ['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = data['label'].nunique())\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = 'base_email_model',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 10,\n",
    "    weight_decay = 0.01,\n",
    "    logging_steps = 50,\n",
    "    save_strategy = 'epoch',\n",
    "    eval_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "    report_to = 'none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model('base_email_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis = 1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "label_to_category = dict(enumerate(data['category'].astype('category').cat.categories))\n",
    "\n",
    "print(classification_report(labels, preds, target_names = list(label_to_category.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_dataset.to_pandas()['email_text'].tolist()\n",
    "test_true_labels = test_dataset.to_pandas()['label'].tolist()\n",
    "\n",
    "errors = [ ]\n",
    "\n",
    "for i, (true, pred) in enumerate(zip(test_true_labels, preds)):\n",
    "    if true != pred:\n",
    "        errors.append({'true': label_to_category[true], 'pred': label_to_category[pred]})\n",
    "\n",
    "errors_data = pd.DataFrame(errors)\n",
    "\n",
    "print('Sample of model mistakes (top 20)')\n",
    "print(errors_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18, 14))\n",
    "sns.heatmap(confusion_matrix(labels, preds), annot = True, cmap = 'Blues', xticklabels = label_to_category.values(), yticklabels = label_to_category.values())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
